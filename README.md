# semantic_concept_embeddings
The code and datasets of "Distilling Semantic Concept Embeddings from Contrastively Fine-Tuned Language Models" presented in SIGIR'23.

# Requirements
- Python 3.7
- transformers == 4.18.0
- scikit-learn == 1.0.2
- faiss == 1.7.2
- pytorch-metric-learning == 1.0.0
- gensim == 4.1.2

# Usage
## Run ConProj

## Run ConFT

## Run ConCN

# Citation
```
@inproceedings{Li_conceptembddings_sigir23,
author = {Li, Na and Kteich, Hanane and Bouraoui, Zied and Schockaert, Steven},
title = {Distilling Semantic Concept Embeddings from Contrastively Fine-Tuned Language Models},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591667},
doi = {10.1145/3539618.3591667},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {216â€“226},
numpages = {11},
keywords = {language models, commonsense knowledge, contrastive learning, word embedding},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}
```
